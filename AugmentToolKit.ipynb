{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -Rf augmentool\n",
        "!git clone  --branch aphrodite-branch https://github.com/e-p-armstrong/augmentool.git"
      ],
      "metadata": {
        "id": "iG5JGXst9nB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd augmentool/"
      ],
      "metadata": {
        "id": "bO6FhMRK9tym",
        "outputId": "8ab8cedc-0a65-4b00-accf-0d98cb57d09d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/augmentool/augmentool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf sentencepiece transformers matplotlib nltk aphrodite-engine\n",
        "!pip install -q condacolab"
      ],
      "metadata": {
        "id": "CPQsksht-9XY",
        "outputId": "dd6513e6-d102-47a7-a929-816fd9df67ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: aphrodite-engine in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.11.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (5.9.5)\n",
            "Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (2.9.2)\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (2.2.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.27.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.12.0)\n",
            "Requirement already satisfied: xformers>=0.0.24 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.0.24)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.7.0)\n",
            "Requirement already satisfied: fschat>=0.2.23 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.2.36)\n",
            "Requirement already satisfied: pydantic==1.10.13 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.10.13)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.109.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (6.8.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.19.0)\n",
            "Requirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (2.2.0)\n",
            "Requirement already satisfied: lark==1.1.8 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.1.8)\n",
            "Requirement already satisfied: pynvml==11.5.0 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (11.5.0)\n",
            "Requirement already satisfied: gguf in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.13->aphrodite-engine) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->aphrodite-engine) (12.3.101)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (3.9.3)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (0.26.0)\n",
            "Requirement already satisfied: markdown2[all] in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (2.4.12)\n",
            "Requirement already satisfied: nh3 in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (0.2.15)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (3.0.43)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (13.7.0)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (1.0.11)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->aphrodite-engine) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->aphrodite-engine) (1.0.7)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->aphrodite-engine) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->aphrodite-engine) (1.4.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->aphrodite-engine) (0.36.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->aphrodite-engine) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->aphrodite-engine) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->aphrodite-engine) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->aphrodite-engine) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->aphrodite-engine) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->fschat>=0.2.23->aphrodite-engine) (1.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat>=0.2.23->aphrodite-engine) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat>=0.2.23->aphrodite-engine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat>=0.2.23->aphrodite-engine) (2.16.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat>=0.2.23->aphrodite-engine) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat>=0.2.23->aphrodite-engine) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat>=0.2.23->aphrodite-engine) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat>=0.2.23->aphrodite-engine) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->aphrodite-engine) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->aphrodite-engine) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->aphrodite-engine) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->aphrodite-engine) (0.17.1)\n",
            "Requirement already satisfied: wavedrom in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->fschat>=0.2.23->aphrodite-engine) (2.0.3.post3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->aphrodite-engine) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat>=0.2.23->aphrodite-engine) (0.1.2)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]->fschat>=0.2.23->aphrodite-engine) (1.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf sentencepiece transformers matplotlib nltk aphrodite-engine\n",
        "!pip install -q condacolab"
      ],
      "metadata": {
        "id": "FkeMG5Rq_Dc6",
        "outputId": "78e189da-5706-4e32-9bca-24b6c1f4d755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: aphrodite-engine in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.11.1.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (5.9.5)\n",
            "Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (2.9.2)\n",
            "Requirement already satisfied: torch==2.2.0 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (2.2.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.27.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.12.0)\n",
            "Requirement already satisfied: xformers>=0.0.24 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.0.24)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.7.0)\n",
            "Requirement already satisfied: fschat>=0.2.23 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.2.36)\n",
            "Requirement already satisfied: pydantic==1.10.13 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.10.13)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.109.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (6.8.2)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.19.0)\n",
            "Requirement already satisfied: triton>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (2.2.0)\n",
            "Requirement already satisfied: lark==1.1.8 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.1.8)\n",
            "Requirement already satisfied: pynvml==11.5.0 in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (11.5.0)\n",
            "Requirement already satisfied: gguf in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (0.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from aphrodite-engine) (1.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.13->aphrodite-engine) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->aphrodite-engine) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->aphrodite-engine) (12.3.101)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (3.9.3)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (0.26.0)\n",
            "Requirement already satisfied: markdown2[all] in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (2.4.12)\n",
            "Requirement already satisfied: nh3 in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (0.2.15)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (3.0.43)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (13.7.0)\n",
            "Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (1.0.11)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from fschat>=0.2.23->aphrodite-engine) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->aphrodite-engine) (4.19.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->aphrodite-engine) (1.0.7)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->aphrodite-engine) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->aphrodite-engine) (1.4.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->aphrodite-engine) (0.36.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai->aphrodite-engine) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->aphrodite-engine) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai->aphrodite-engine) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->aphrodite-engine) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai->aphrodite-engine) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->fschat>=0.2.23->aphrodite-engine) (1.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat>=0.2.23->aphrodite-engine) (0.2.13)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat>=0.2.23->aphrodite-engine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat>=0.2.23->aphrodite-engine) (2.16.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat>=0.2.23->aphrodite-engine) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat>=0.2.23->aphrodite-engine) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat>=0.2.23->aphrodite-engine) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat>=0.2.23->aphrodite-engine) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->aphrodite-engine) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->aphrodite-engine) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->aphrodite-engine) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray>=2.9->aphrodite-engine) (0.17.1)\n",
            "Requirement already satisfied: wavedrom in /usr/local/lib/python3.10/dist-packages (from markdown2[all]->fschat>=0.2.23->aphrodite-engine) (2.0.3.post3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->aphrodite-engine) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat>=0.2.23->aphrodite-engine) (0.1.2)\n",
            "Requirement already satisfied: svgwrite in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]->fschat>=0.2.23->aphrodite-engine) (1.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Z4LUy_9PjX"
      },
      "source": [
        "\n",
        "\n",
        "# Welcome to Augmentoolkit\n",
        "\n",
        "This notebook is where you generate all your data.\n",
        "\n",
        "Augmentoolkit is meant to allow instruct-tuned models to learn from books, even using themselves to generate new data through a sort-of bootstrapping method. It is meant to stop model creators from having to work as data annotators, and not actual model trainers. It is meant to allow anyone to make their own high-quality dataset with thousands of entries.\n",
        "\n",
        "## Quickstart:\n",
        "\n",
        "- Get this notebook and the other repo code onto a machine with the power to run Airoboros-l2-70b-3.1.2.Q4_K_M\n",
        "- Run all the cells below and watch as the notebook generates questions, answers, and conversations based on Principles of Chemistry, Simple Sabotage, and Introduction to Philosophy.\n",
        "\n",
        "If you want to add your own texts, follow the instructions in list item #1 above.\n",
        "\n",
        "### Note: this notebook makes roughly 1/3 characters generated to be **mildly NSFW** by default. You will need to modify the character personality code in `./generation_functions/special_instructions.py` or use \"Assistant mode\" if you want something cleaner.\n",
        "\n",
        "## Customization:\n",
        "### Here are some ways you can adapt this notebook to your use case, along with a brief description of how to do so, arranged in increasing order of difficulty (this information is also available in the README):\n",
        "1. ***Change the source texts used to generate training data.*** You can do this in the cell right below this one. **IMPORTANT** the filenames of these should be formatted in a specific way, since the filenames are used as part of the prompts and in at least one regex. You need to have them be like: `[textname], by authorname`. You can also include the publication date after the author name if you want, but note that this will tend to bias most of the characters to live in the era of the textbook, which may or may not be what you want.\n",
        "\n",
        "2. ***Change the personalities of the characters generated.*** Currently, when generating characters for the multiturn conversation step, three randomly-selected traits are appended to the \"special instructions\" set of the prompt to constrain what kind of character is generated by the model. Depending on what kind of model you want to make, or even just if your preferences vary, then you will probably want to modify this a bit. You can do so in `./generation_functions/special_instructions.py`. A more in-depth description of the trait-axis system that I (over)thought up is available in the comments of that file.\n",
        "\n",
        "3. ***Change the constants.*** There are a few constant values in this notebook, and in `./generation_functions/constant_values.py`. These constants are tested, but if your use case requires special settings (e.g., you want to make conversations from more permutations of existing questions; or you think the character counts for the \"duplicate question/answer\" validation functions are too restrictive) then feel free to change the related setting. The most intuitive and least-likely-to-break-anything settings to change are rearrangements_to_take and double_check_counter. Beyond that... you'll need to figure out what the function does before changing it if you expect it to run.\n",
        "\n",
        "4. ***Assistant Mode*** Technically this could be considered part of 3), but it's different enough that I feel it warrants separate explanation. By default, the notebook is configured to produce RP-style data; \"Assistant mode\" is something you can toggle in the settings cell immediately below this one, which skips character and scenario generation and answers every question in a chat between a user and a helpful AI assistant (with no personality). In the limited testing I have done with this, **it seems that assistant mode is simple enough to work with 13b models** such as Flatorcamaid by Ikari. So if your compute or time are very limited, or you are using this for a more professional use case, feel free to turn this on.\n",
        "\n",
        "5. ***Change the model.*** This is as simple as switching the LOGICAL_MODEL value out for another one, but your mileage may vary significantly. My personal recommendation is to use [FlatOrcamaid](https://huggingface.co/TheBloke/FlatOrcamaid-13B-v0.2-GGUF/tree/main) (helluva name, I know) for the small model, and [Airoboros-l2-70b-3.1.2.Q4_K_M](https://huggingface.co/TheBloke/Airoboros-L2-70B-3.1.2-GGUF) for the large model. You need 12k context on your model, but Aphrodite Engine should handle the RoPE scaling automatically. Check `augmentoolkit/generation_functions/engine_wrapper.py` to customize the engine's parameters.\n",
        "\n",
        "6. ***Change the examples.*** If you change the examples you can completely overhaul what this notebook does, but this requires a lot of prompting skill and possibly huge amounts of time to get it working again (source: most of my last three months were spent prompting, and most of this prompting was spent on the examples). Unless you want to convert this notebook from question-and-answer generation to some completely other task, I'd recommend changing only the conversation generation prompts -- they're a bit less finnicky, and if you just want to change the kind of characters generated (maybe you want a different writing style) that's where you'd find the differences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhAulxfJ9PjY"
      },
      "source": [
        "## NOTE\n",
        "You will want to turn off USE_SUBSET if you are doing a proper run over an entire text. It's on by default so you can iterate faster in the preparatory stages of dataset generation (and so that you can see the magic happen faster when you first use Augmentoolkit :) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LPAoHCNU9PjZ"
      },
      "outputs": [],
      "source": [
        "# NOTE NOTEBOOK SETTINGS AND CONSTANTS (some script file constants are in generation_functions/constants.py)\n",
        "\n",
        "# Put your desired quant of your desired model in the relevant directories\n",
        "\n",
        "\n",
        "# \"airoboros-l2-70b-3.1.2.Q4_K_M.gguf\" <- recommended for the large logical model\n",
        "# \"flatorcamaid-13b-v0.2.Q8_0.gguf\" <- recommended for the normal logical model\n",
        "# A6000s on Vast.ai are a good choice for running this notebook\n",
        "\n",
        "LOGICAL_MODEL = \"TheBloke/Airoboros-L2-70B-3.1.2-GGUF/blob/main/airoboros-l2-70b-3.1.2.Q5_K_M.gguf\"  # model used for decision-making and base question generation (should be \"smart\")\n",
        "\n",
        "LARGE_LOGICAL_MODEL = \"TheBloke/Airoboros-L2-70B-3.1.2-GGUF/blob/main/airoboros-l2-70b-3.1.2.Q5_K_M.gguf\"\n",
        "\n",
        "ASSISTANT_MODE = True  # change to true if you want all conversations to be with an \"AI language model\" and not characters. Useful for more professional use cases.\n",
        "\n",
        "DOUBLE_CHECK_COUNTER = 3  # Set to 1 to check outputs only once; set to 2 to check twice; set to 3 to check thrice, etc. Set to 0 to break everything in vet_question_loop() and elsewhere. Set to -1 and cause the universe to implode?\n",
        "\n",
        "USE_SUBSET = True # Set to True if you want to use only a small subset of the text, to test whether it plays nicely with the current setup of the notebook\n",
        "\n",
        "REARRANGEMENTS_TO_TAKE = 3  # How many of the possible permutations of tuples in a group to take and make multiturn convs out of. Adjust higher to get more data out of less text, but it might be a bit repetitive. NOTE your eval loss will be basically worthless if you aren't careful with how you shuffle your dataset when you're about to train.\n",
        "\n",
        "source_texts = [\n",
        "    \"Simple Sabotage, by the Office of Strategic Services, published 1944.txt\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcvx_k5C9PjZ"
      },
      "source": [
        "### Start running the Aphrodite server (additional requirements: requests and aphrodite)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCCVdmYo9PjZ"
      },
      "source": [
        "## Below: Defines and imports functions that you will probably use no matter what cells in the notebook you choose to run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_qCxXbp9PjZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import uuid\n",
        "\n",
        "# This is in no way best practices, but all my prompts being searchable and separate files is a good way to make my life easier.\n",
        "import pkgutil\n",
        "import importlib\n",
        "import sys\n",
        "from tqdm import asyncio as tqdmasyncio\n",
        "\n",
        "# We have to define this up here so that two-step generation works, you'll see later.\n",
        "multi_turn_convs_info_dir = \"./multi_turn_convs_info\"  # we generate all the information fed to the multiturn prompt, and generate the actual multiturn prompt, separately; since every step but the last is capable of being done by a 13b\n",
        "\n",
        "sys.path.append(\"./generation_functions\")\n",
        "sys.path.append(\"./control_flow_functions\")\n",
        "\n",
        "import augmentoolkit.generation_functions as generation_functions  # This is the package directory\n",
        "from augmentoolkit.control_flow_functions import control_flow_functions\n",
        "\n",
        "# First, import all modules so they can be reloaded\n",
        "for _, module_name, _ in pkgutil.iter_modules(\n",
        "    generation_functions.__path__, generation_functions.__name__ + \".\"\n",
        "):\n",
        "    importlib.import_module(module_name)\n",
        "\n",
        "# Now, reload each module and import all callable attributes\n",
        "for _, module_name, _ in pkgutil.iter_modules(\n",
        "    generation_functions.__path__, generation_functions.__name__ + \".\"\n",
        "):\n",
        "    # Reload the module\n",
        "    module = importlib.reload(sys.modules[module_name])\n",
        "    # Iterate through each attribute in the reloaded module\n",
        "    for attribute_name in dir(module):\n",
        "        # Retrieve the attribute\n",
        "        attribute = getattr(module, attribute_name)\n",
        "        if callable(attribute):\n",
        "            # If it's callable, it's a function or class, so you set it in the globals dictionary\n",
        "            globals()[attribute_name] = attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4a6-FIU9PjZ"
      },
      "outputs": [],
      "source": [
        "# Start Aphrodite Engine\n",
        "engine_wrapper = EngineWrapper(model=LOGICAL_MODEL, quantization=\"gptq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLwmJa8L9Pja"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"Gryphe/MythoMax-L2-13b\"\n",
        ")  # It doesn't matter what model goes here as long as it is sentencepiece\n",
        "\n",
        "sentence_chunks = []\n",
        "for source_text in source_texts:\n",
        "    sentence_chunks += control_flow_functions.sentence_chunking_algorithm(source_text, tokenizer)\n",
        "\n",
        "conversions = [(\"\\n\", \" \"), (\"  \", \" \")]\n",
        "\n",
        "paragraphs_processed = [\n",
        "    (control_flow_functions.fix_text(conversions, seq[0]), seq[1]) for seq in sentence_chunks\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAApAy1q9Pja"
      },
      "source": [
        "#### Inspect various features of the text you have fed in to see if it came out alright-ish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9ExMCUA9Pja"
      },
      "outputs": [],
      "source": [
        "len(paragraphs_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsC9ooCe9Pja"
      },
      "outputs": [],
      "source": [
        "paragraphs_processed[5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEOpd5oI9Pja"
      },
      "source": [
        "#### The below cell will take a while to start generating for various screwy async reasons. It's doing its job, it just schedules everything first and THEN you see results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QumQgLjy9Pja"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import asyncio\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "output_dir = \"./worthy_for_questions\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Determine which paragraphs are worthy of making questions from\n",
        "judged_worthy_for_questions = []\n",
        "\n",
        "await control_flow_functions.filter_all_questions(paragraphs_processed, judged_worthy_for_questions, engine_wrapper, output_dir, USE_SUBSET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvuXARLE9Pja"
      },
      "outputs": [],
      "source": [
        "filtered_worthy_for_questions = control_flow_functions.filter_and_graph(judged_worthy_for_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC0vQQca9Pja"
      },
      "outputs": [],
      "source": [
        "print(filtered_worthy_for_questions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pid-4p2q9Pja"
      },
      "source": [
        "### The cell below begins generating questions. SOME OF THESE MAY FAIL and have to retry due to model errors (the aphrodite branch cannot use grammars). But if you let it run you will see that the vast majority eventually get through.\n",
        "\n",
        "In short, don't get scared by tracebacks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmSM0Xj_9Pja"
      },
      "outputs": [],
      "source": [
        "# control flow\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Directory for QA tuples\n",
        "qa_tuples_dir = \"./qatuples_raw\"\n",
        "if not os.path.exists(qa_tuples_dir):\n",
        "    os.makedirs(qa_tuples_dir)\n",
        "\n",
        "# Initialize vetted_qa_tuples\n",
        "vetted_qa_tuples = []  # tuple list of qa tuples that have been judged good\n",
        "\n",
        "# Attempt to initialize filtered_worthy_for_questions\n",
        "try:\n",
        "    _ = filtered_worthy_for_questions\n",
        "except NameError:\n",
        "    filtered_worthy_for_questions = []\n",
        "\n",
        "if not filtered_worthy_for_questions:\n",
        "    # Load all files in the qa_tuples_dir if filtered_worthy_for_questions is not initialized\n",
        "    existing_files = glob.glob(os.path.join(qa_tuples_dir, \"*.json\"))\n",
        "    for file_path in existing_files:\n",
        "        with open(file_path, \"r\") as file:\n",
        "            qa_tuple = tuple(json.load(file))\n",
        "        vetted_qa_tuples.append(qa_tuple)\n",
        "else:\n",
        "    tasks = [control_flow_functions.generate_qatuples_from_para(\n",
        "        idx,\n",
        "        para,\n",
        "        engine_wrapper=engine_wrapper,\n",
        "        vetted_qa_tuples=vetted_qa_tuples,\n",
        "        qa_tuples_dir=qa_tuples_dir,\n",
        "        double_check_counter=DOUBLE_CHECK_COUNTER) for idx,para in enumerate(filtered_worthy_for_questions)]\n",
        "    for future in tqdmasyncio.tqdm.as_completed(tasks):\n",
        "            await future\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmq6Is859Pjb"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    \"-------------- QUESTIONS CREATED ------------- STATS SO FAR (may be wrong if run was continued from interruption):\"\n",
        ")\n",
        "nones = list(filter(lambda x: x[0] is None, vetted_qa_tuples))\n",
        "print(f\"Nones: {len(nones)}\")\n",
        "print(f\"Non-nones: {len(vetted_qa_tuples) - len(nones)}\")\n",
        "print(f\"Total: {len(vetted_qa_tuples)}\")\n",
        "# filter out all None values\n",
        "vetted_qa_tuples = [qa for qa in vetted_qa_tuples if qa[0] is not None]\n",
        "print(\"---------------- ONTO EXAMPLES GENERATION-------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nO1mTqS9Pjb"
      },
      "outputs": [],
      "source": [
        "# Check for and fix the common mistake: mentioning \"the text\".\n",
        "writepath = \"./qatuples_revised\"\n",
        "import json\n",
        "\n",
        "# Assuming vetted_qa_tuples is a list that might or might not exist\n",
        "try:\n",
        "    _ = vetted_qa_tuples\n",
        "except NameError:\n",
        "    vetted_qa_tuples = []\n",
        "\n",
        "# Load all files at the start if vetted_qa_tuples is empty\n",
        "if not vetted_qa_tuples:\n",
        "    # Check if the directory exists\n",
        "    if os.path.exists(writepath):\n",
        "        # List all files in directory\n",
        "        for file_name in os.listdir(writepath):\n",
        "            file_path = os.path.join(writepath, file_name)\n",
        "            try: # for each file already generated, see if it succeeded or failed; if it succeeded, append its contents; if it failed, append None for stats logging\n",
        "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    content = f.read()\n",
        "                    print(f\"Loading file: {file_path}\")\n",
        "                    if content == \"failed\":\n",
        "                        vetted_qa_tuples.append(None)\n",
        "                    else:\n",
        "                        try:\n",
        "                            data = json.loads(content)\n",
        "                            vetted_qa_tuples.append(\n",
        "                                (data[0], data[1], data[2], data[3])\n",
        "                            )\n",
        "                        except json.JSONDecodeError:\n",
        "                            print(\"JSON decode error with the contents:\", content)\n",
        "                            vetted_qa_tuples.append(None)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading {file_path}: {e}\")\n",
        "\n",
        "else:\n",
        "    old_tuples = vetted_qa_tuples.copy()\n",
        "    tasks = [control_flow_functions.repair_qatuple_context(idx, tup, engine_wrapper, writepath, vetted_qa_tuples) for idx, tup in enumerate(vetted_qa_tuples)]\n",
        "    for future in tqdmasyncio.tqdm.as_completed(tasks): # TODO Change to TQDM\n",
        "        await future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-ymm5XW9Pjb"
      },
      "outputs": [],
      "source": [
        "# Print stats related to revised qatuples, and filter out nones (questions that were unanswerable due to lack of context).\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"-------------- QUESTIONS REVISED ------------- STATS SO FAR:\")\n",
        "nones = list(filter(lambda x: x is None, vetted_qa_tuples))\n",
        "print(f\"Nones: {len(nones)}\")\n",
        "print(f\"Non-nones: {len(vetted_qa_tuples) - len(nones)}\")\n",
        "print(f\"Total: {len(vetted_qa_tuples)}\")\n",
        "# filter out all None values\n",
        "vetted_qa_tuples = [qa for qa in vetted_qa_tuples if qa is not None]\n",
        "print(\"---------------- ONTO EXAMPLES GENERATION-------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-OEQrZf9Pjb"
      },
      "outputs": [],
      "source": [
        "qa_tuples_by_paragraph = control_flow_functions.group_by_text(vetted_qa_tuples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3egW32dY9Pjb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(multi_turn_convs_info_dir):\n",
        "    os.makedirs(multi_turn_convs_info_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-GH2Rbm9Pjb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "multi_turn_convs_info = []\n",
        "\n",
        "\n",
        "tasks = [control_flow_functions.create_info(idx,group,engine_wrapper, ASSISTANT_MODE, multi_turn_convs_info,multi_turn_convs_info_dir, REARRANGEMENTS_TO_TAKE) for idx,group in enumerate(qa_tuples_by_paragraph)]\n",
        "for future in tqdmasyncio.tqdm.as_completed(tasks):\n",
        "    await future"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bhxu2rOE9Pjb"
      },
      "source": [
        "# Stop Here, Restart the Notebook, and Reimport Everything Using Cell #2 IF you are doing 2-step Generation (where you do the easy bits with a small model, and the hard bit below with a large one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eeZb0yj9Pjb"
      },
      "outputs": [],
      "source": [
        "engine_wrapper = EngineWrapper(model=LARGE_LOGICAL_MODEL, quantization=\"gptq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WcYQkYgO9Pjb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "convs_info = control_flow_functions.read_json_files_info(multi_turn_convs_info_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klOpAOEu9Pjb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "import itertools\n",
        "import asyncio\n",
        "\n",
        "multi_turn_convs_dir = \"./multi_turn_convs\"\n",
        "if not os.path.exists(multi_turn_convs_dir):\n",
        "    os.makedirs(multi_turn_convs_dir)\n",
        "\n",
        "multi_turn_convs = []\n",
        "\n",
        "tasks = [control_flow_functions.create_conversation(idx,info, engine_wrapper, multi_turn_convs, multi_turn_convs_dir, ASSISTANT_MODE) for idx,info in enumerate(convs_info)]\n",
        "for future in tqdmasyncio.tqdm.as_completed(tasks):\n",
        "    await future"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaO_C12A9Pjb"
      },
      "source": [
        "# Yay! Now you have a dataset!\n",
        "### GPT wrote the cell below. I think it successfully converts things to ShareGPT format for use with axolotl, but I am not sure because I don't know that format very well and haven't used Axolotl. However, the json produced by the second function looks fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrmkKOQq9Pjb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Make ShareGPT-format dataset (I think, still need verification it actually works)\n",
        "control_flow_functions.convert_directory_to_list(\"./multi_turn_convs/\")\n",
        "# Make dataset in a format that has all the information. See README for details on this format.\n",
        "control_flow_functions.convert_directory_and_process_conversations(\"./multi_turn_convs/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWz9gc1G9Pjc"
      },
      "outputs": [],
      "source": [
        "with open(\"./processed_master_list.json\") as f:\n",
        "    first = f.read()\n",
        "    data = json.loads(first)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w99mY8yp9Pjc"
      },
      "outputs": [],
      "source": [
        "# For curiosity's sake, you can find out how many lines of dialogue you generated\n",
        "def filter_and_flatten(lst):\n",
        "    # Initialize an empty list to hold the flattened elements\n",
        "    flat_list = []\n",
        "\n",
        "    # Loop through each sublist in the main list\n",
        "    for sublst in lst:\n",
        "        # Check if the first element of the sublist is itself a list (subsublist1)\n",
        "        if isinstance(sublst[0], list):\n",
        "            # Extend the flat_list with the elements from subsublist1\n",
        "            flat_list.extend(sublst[0])\n",
        "\n",
        "    return flat_list\n",
        "\n",
        "\n",
        "len(filter_and_flatten(data))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}